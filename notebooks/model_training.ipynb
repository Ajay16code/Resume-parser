{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Resume vs Job Description Classifier Training\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This notebook loads data, preprocesses text, builds sentence embeddings using `all-MiniLM-L6-v2`, trains a Logistic Regression classifier, evaluates metrics, and exports model artifact.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "import re\nimport string\nfrom pathlib import Path\n\nimport joblib\nimport numpy as np\nimport pandas as pd\nfrom sentence_transformers import SentenceTransformer\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import (\n    accuracy_score,\n    confusion_matrix,\n    f1_score,\n    precision_score,\n    recall_score,\n)\nfrom sklearn.model_selection import train_test_split\n\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "DATA_PATH = Path('../data/sample_dataset.csv')\nMODEL_PATH = Path('../models/resume_classifier.pkl')\n\ndf = pd.read_csv(DATA_PATH)\ndf.head()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "STOPWORDS = {\n    'a', 'an', 'the', 'and', 'or', 'to', 'for', 'with', 'in', 'on', 'at', 'of', 'is', 'are'\n}\n\ndef clean_text(text: str) -> str:\n    text = text.lower()\n    text = text.translate(str.maketrans('', '', string.punctuation))\n    text = re.sub(r'\\s+', ' ', text).strip()\n    tokens = [token for token in text.split() if token not in STOPWORDS]\n    return ' '.join(tokens)\n\ndf['resume_clean'] = df['resume_text'].astype(str).apply(clean_text)\ndf['job_clean'] = df['job_description'].astype(str).apply(clean_text)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "embedder = SentenceTransformer('all-MiniLM-L6-v2')\n\nresume_embeddings = embedder.encode(df['resume_clean'].tolist())\njob_embeddings = embedder.encode(df['job_clean'].tolist())\n\nX = np.hstack([resume_embeddings, job_embeddings])\ny = df['label'].values\n\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.2, random_state=42, stratify=y\n)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "clf = LogisticRegression(max_iter=1000)\nclf.fit(X_train, y_train)\n\ny_pred = clf.predict(X_test)\n\nprint('Accuracy:', accuracy_score(y_test, y_pred))\nprint('Precision:', precision_score(y_test, y_pred, zero_division=0))\nprint('Recall:', recall_score(y_test, y_pred, zero_division=0))\nprint('F1 Score:', f1_score(y_test, y_pred, zero_division=0))\nprint('Confusion Matrix:\\n', confusion_matrix(y_test, y_pred))\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "MODEL_PATH.parent.mkdir(parents=True, exist_ok=True)\njoblib.dump(clf, MODEL_PATH)\nprint(f'Model saved to: {MODEL_PATH.resolve()}')\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}